\section{Introduction}

To begin, let us take a look at a particular logic puzzle:

{\small\textit{"On a certain fictional island there are only two types of inhabitants: the knights always tell the truth, and the knaves who always tell lies. One day, a logician pays a visit to a small family of three on the island. While the four are having dinner, the logician asks whether the dad is a knight or a knave. The dad says "Ask my son and he will tell you the truth". The son then says "We are all of the same type". Finally, the mom says "You have to excuse us, one of them cannot tell the truth". Can you tell which family members are knight, and which are knaves?"}}

If the dad is telling the truth, then the son's statement is true and so the entire family are knights. However, that must mean the mom is also telling the truth, and they cannot all be knights (a contradiction). Therefore, the dad must be lying, and so is the son. Following from the son's lie it must be the case that the family has both types of people. Since two family members are already determined to be knaves, the mom must be a knight.

What if we start first from the mom? Suppose she is telling lies, then both the son and dad are telling the truth. However, the son's statement must be wrong since the family is mixed (a contradiction). Therefore, the mom must be telling the truth, and either the dad or the son is lying (or both). If the son is telling the truth, then it immediately follows he is lying, since according to him the dad must be telling the truth and the mom's statement now cannot be true. Therefore, the son is lying and so is the dad for referring to him. This conclusion is consistent with the first approach.

Puzzles like these are called \textit{knights and knaves} puzzles, and they were popularized by (\cite{knight}). In coming up with a solution, we can see a relatively simple mechanism in play. First, we determine one possible value of an unknown variable (if there is none left, abandon the branch). Second, we check if the state is logically consistent; if yes, loop back to the first step; if no, undo the choice made in the first step, choose something else, and carry on with the algorithm. The process terminates either when there is no longer any choice to be made, in which case we can return the state as one possible answer; or when we have exhausted all possibilities and no choice can lead to a consistent state, in which case we fail.

This technique where the program needs to handle many different possibilities is called \textbf{backtracking}. \textbf{Logic programming languages} offer to make backtracking implicit; programmers only need to declare the rules, and the computer will automatically generate all states consistent within those rules. Logic languages often give elegant solutions to a wide class of problems involving search and enumeration.

Logic programming dates back to 1972, when the Prolog (\textbf{pro}grammation en \textbf{log}ique) language was first invented by Alain Colmerauer and Phillipe Roussel (\cite{early-prolog}). At the time of its birth, logic programming was considered by some to be the future, especially in Japan. In the 1970's, the Japanese International Trade and Industry (MITI) wanted to take over the computer industry with a new Fifth Generation Computing System Project (named ICOT), aiming to replace conventional algorithmic computing with constraint-based programming techniques. The project soon failed, however, because these languages were not fast enough to compete with other mainstream object-oriented languages like Java and C\#. Carl Hewitt summed up the situation by the comment "\textit{Computation is not subsumed by deduction.}" (\cite{logic-fail})

Despite its name, Prolog was not just about logic and its users generally do not shy away from its extra-logical features. These features on one hand can greatly enhance performance, but they can also make programs less declarative, incomplete and even unsound. On the other hand, \textbf{relational programming} is a discipline of logic programming in which these features are left out. This guarantees that all answers are returned even when all arguments are logic variables. Additionally, the same set of answers are returned regardless of the order in which rules are applied, like how the logic puzzle given earlier can be solved in two different ways. The design philosophy of \textbf{miniKanren} puts great emphasis on this discipline\footnote{"Kanren" is literally Japanese for "relation".}, and this text will discuss some of its strengths, weaknesses, and applications. (\cite{byrdphd})

Technically speaking, miniKanren is not a language with its own compiler or interpreter; it is instead a family of languages embedded in a great variety of other host languages. In this paper, we choose to use the Scheme implementation for three reasons. The first reason is that it is the canonical version mentioned in almost every academic paper written on the language. The second reason is that Scheme's macro makes the syntax less clunky and more natural to read and write. And last but not least, Scheme is an extremely elegant language with minimal syntax (some would even say no syntax), hence it is trivial to briefly specify a small portion of the language to be used in this text.

The layout of this paper is as follow: Section ... will specify a subset of Scheme. Section ... discusses miniKanren. Finally, we take a look at some problems which demand backtracking; give a solution if there is one; and analyze why the problem is hard if it cannot be simply solved.